
\section{UNIVERSAL ACCESS AND COMPUTATIONAL THINKING}

%% \makequotation{Thinking like a computer scientist means more than being able to 
%% program a computer. It requires thinking at multiple levels of
%% abstraction.}{Jeannette M. Wing, \emph{Computational
%%     Thinking}~\cite{wing_computational_thinking}} 

\makequotation{I think everyone should learn how to program a computer,
  because it teaches you how to think.}{Steve Jobs~\cite{steve_jobs_interview}}


For a while in the 80s and 90s, ``computer literacy'' meant familiarity
with productivity tools such as email, Web browsers, word processors,
spreadsheets, and so on.
But within the computer science community, discussions about computer
literacy have always been framed quite differently.
In 1996, MIT computer scientist and educator \w{Seymour Papert} coined
the term \w{computational thinking} to describe the mindset and types of
techniques that characterize a computer scientist's view of
problem-solving.
Ten years later, an
\href{http://www.cs.cmu.edu/afs/cs/usr/wing/www/publications/Wing06.pdf}{influential
op-ed} by Carnegie-Mellon University computer scientist Jeannette Wing
argued for the practical importance of computational thinking and
problem solving~\cite{wing_computational_thinking}.

In 1962, Tom Kurtz, a mathematics professor at Dartmouth College who was
concerned about
all of these same issues, approached his department chair John Kemeny
with a remarkably farsighted vision: Since computers were clearly going
to be important in everyday life, \emph{all} Dartmouth students should
become computer literate.
At the time,
computers were room-filling mainframes, and were so expensive
that they could only be rented, at a monthly cost typically exceeding a
professor's salary.
Universities that had computers charged students for actual
computer time used, incentivizing them to minimize usage.
Kurtz's proposal to give students
\emph{unlimited} computer access, just as they had unlimited library borrowing privileges,
was especially radical at this small liberal arts 
college: though 75\% of the students pursued nontechnical majors~\cite{goto},
Kurtz was convinced they should all learn simple programming in order to understand
computers, which he believed would soon influence every aspect
of daily life.

Like many prestigious universities, Dartmouth could mitigate the cost of
the computers themselves by cultivating good relationships with
computer manufacturers and private and public benefactors.
But Kurtz would also need to overcome a technology problem.
Computer programmers in 1962 had to prepare programs on decks of punched cards,
submit them to a technician,
% TBD picture of punched card
and come back hours or days later to retrieve a printout with
the results of their program run.  (As often as not, the printout
would reveal that there had been an error in the program, and the
hapless programmer would have to start the process over again.)
%% (It may seem ridiculous today to wait hours or days for the results of a
%% running a computer program, but given the speeds of 
%% communication and transportation in 1962, it was normal for
%% business information to be a few days out of
%% date~\cite{ceruzzi}.) 
%% If the results were botched because of a simple error in the program,
%% the programmer would re-punch the offending cards, resubmit the job, and
%% again wait hours or days for a result.
%% This method of working, called \w{batch processing}, guaranteed the
%% computer would never be idle as long as there was a long queue of user
%% jobs waiting.
Such \emph{batch processing} favored efficient use of (expensive) computer time rather
than (cheap) programmer time,
but Kurtz feared that liberal arts students with no
extrinsic career motivation to learn computing would be unwilling
to endure these rituals.

Fortunately, a technical milestone saved the day.
The ability to \w[Computer multitasking]{multitask} is common on today's
PC operating systems: multiple apps can be open
simultaneously, and apps can even do work ``in the background,''
such as when a mail program
retrieves mail even while the user isn't
directly interacting with the mail program's UI.
An MIT group had been developing an experimental technology called
\w{timesharing}~\cite{corbato62timesharing}, in which a computer
switches its attention many times per second among 
different users.
If it did so more quickly than
users could read or type, each user would have the illusion that the computer
was waiting only on them.  That is, the computer would feel
interactive, ``instantly'' responding to each user's commands.
Professor John McCarthy, leader of the group, easily persuaded Kurtz
and Kemeny that such interactive 
use would be perfect for education because it would allow
students to get
immediate feedback, eliminating the annoying rituals of batch
processing that might discourage beginners.


Timesharing would eventually turn out to be a revolutionary
technological innovation, foreshadowing not only user-friendly PCs but what we now call cloud
computing.
But timesharing wasn't taken seriously in industry at the time, since batch
processing provided a more efficient use of the expensive computer's
time.  So supporting
timesharing required reprogramming the computer's operating
system to enable multitasking---which is what MIT was doing with its
experimental Project~MULTICS, for Multiplexed Information and
Computing Service.


  \begin{tangent}
\emph{\textbf{Note:} Tangents are technical asides that may be of
  interest to some readers, but can be safely skipped without missing any of the story.}

%% In fact, IBM's landmark System/360 line of computers, on which the
%% company had (successfully) staked its future in business computing, was rather visibly
%% rejected by MIT in 1964: since it was designed for batch processing,
%% it lacked a hardware feature (hardware-assisted 
%% address translation) that MULTICS relied on~\cite{ibm360history}.  
While MULTICS was
criticized for being overly complex, it pioneered ideas that influenced
all later operating systems, including a
hierarchically-organized file system, dynamic linking of libraries, 
kernel vs.\ user mode program execution, and
separate memory mapping for each process.
Some of these ideas were carried forward by researchers at Bell Labs
(which pulled out of the project in 1969) in its experimental OS 
humorously called Unics (for
``Uniplexed Information and Computing System'', later respelled Unix), suggesting the much simpler
system's suitability for only a single user.  Unix carefully selected
and refined some of the best ideas in MULTICS, and ironically
became the most influential \emph{multiuser} (and multitasking) OS.
  \end{tangent}

So Dartmouth decided to
follow MIT's lead, acquiring a General Electric computer
and creating their own timesharing
operating system for it.
Dartmouth's timesharing system was ultimately so successful that it
catapulted GE into a new timesharing business that was profitable for a
few years, and led GE to later offer Dartmouth a brand-new model
computer in exchange for collaboration on re-creating timesharing and
BASIC on it.

%% ASR-33 internals in action: https://www.youtube.com/watch?v=11Bcfr8zBvg
%% ASR-33 in action: https://www.youtube.com/watch?v=izC9rIvVnE0

Another challenge was that
while timesharing would in principle allow many students to use the
computer interactively at the same time, each student
would need their own terminal or ``station'' for typing in programs.  In batch
processing, the ``stations'' were inexpensive card-punch machines
that weren't connected to the computer itself, but were used by programmers
to convert their programs into punched-card decks.  In interactive
computing, each station would be connected ``live'' to the computer.
In 1964, video display terminals that could do this were still a decade away.
%% and popular printing terminals
%% were slow and expensive---the
%% Friden Flexowriter printed only 10 characters per second and
%% \href{http://retrotechnology.com/herbs_stuff/flex_behr.html}{cost
%%   \$2500-4000}, or nearly \$20,000 in 2014 dollars.
Fortunately, the Teletype Corporation had recently designed a rugged and
inexpensive ``teleprinter''---a device that combines a keyboard with a
printer mechanism---for the US~Navy.
Teletype made the ASR-33 teleprinter
available to the retail market in 1963 for about \$400, $1/4$ the price of
competing teleprinters, and inexpensive enough for Dartmouth to equip
its new timesharing computer lab.

  \picfigure{figs/ASR33.jpg}{fig:ASR33}{Over half a million Teletype ASR-33s
   were sold before it was discontinued in 1981.
  Its distinctive uppercase-only font is used in the section headings of
  this article.
  \href{https://youtu.be/ObgXrIYKQjc}{See a clip of one in action$\nearrow$} and
  try to
  imagine the noise level in a room full of these.}

So BASIC was born just when the rapid shift from batch processing to
timesharing began, and as a result
was the first programming language to include a command that made
the program pause and wait for the user to type
something.  Such a concept made no sense in batch processing and was
absent from the high level languages such as FORTRAN and COBOL that had
been developed up to that time.
 
