%% Copyright (C) 2013 by Armando Fox.  All rights reserved.

\documentclass{article}

\usepackage{ifthen}
\usepackage{xstring} % needed by wikipedia macro
\usepackage{fullpage}
\usepackage{hyperref}
\usepackage{fancybox}
%\usepackage[square,comma,authoryear]{natbib}
\usepackage{graphicx}

\usepackage[T1]{fontenc}

\title{In Praise of BASIC: The Cultural Impact of the World's Most
  Maligned Programming Language}
\author{Armando Fox}

\begin{document}
\input{macros}
\maketitle

\makequotation{It is practically impossible to teach good programming to
  students that have had a prior exposure to BASIC: as potential
  programmers they are mentally mutilated beyond hope of
  regeneration.}{Edsger W. Dijkstra, Turing Award winner}

%% \makequotation{\ldots the teaching of BASIC should be rated as a
%%   criminal offence: it mutilates the mind beyond recovery.}{Edsger
%%   W. Dijkstra, Turing Award winner}

\makequotation{I think it's fair to say that more persons in the world know how to
write simple programs in BASIC than in any other language. It is true
that most of them are probably still unable to vote or buy a drink.  And
if FORTRAN is the lingua franca, then certainly it must be true that
BASIC is the lingua playpen.}{Thomas E. Kurtz, co-creator of BASIC, in
  1981~\cite{hopl}} 

Much has been written over the decades about the democratization of
computers thanks to Moore's Law, but what has been overlooked is that up
until the consumer Internet appeared in around 1995, BASIC was present
at every milestone, and played a pivotal role in empowering generations
of programmers.
Yet BASIC is probably one of the most maligned programming languages
that achieved widespread use.
In \emph{Back to BASIC}~\cite{backtobasic}, the language's co-creators
object that the criticisms leveled at the ``Street BASICs''---the motley
collection of BASIC dialects that proliferated when BASIC became the
\emph{lingua franca} of PCs---would not apply to the original language
they had created.
This defense seems doubtful, since the original language did include
\T{GO~TO}, which Dijkstra famously railed against (cite: GOTO
considered harmful).

Nonetheless, even if we grant the criticisms,
I will argue that they miss the goal of the
language, which was to expose as many non-programmers as possible to
programming---something it accomplished beyond its creators' wildest dreams,
if not in the precise way they had envisioned.

BASIC introduced an entire generation of
programmers to programming.  It may have inculcated many ``bad'' habits that
structured languages tried to break, but it taught us computational
thinking.    It's time the true story was told.

Further, I'll reclaim the term ``Street
BASIC'' to mean exactly what the language's creators mean but without
the negative connotations.

Current incarnations of BASIC, such as Microsoft's VB.net, bear little resemblance to
their common ancestor.

%% TBD need to give due credit to Gates, Allison and PC makers here

\section{UNIVERSAL ACCESS AND COMPUTATIONAL THINKING}

%% \makequotation{Thinking like a computer scientist means more than being able to 
%% program a computer. It requires thinking at multiple levels of
%% abstraction.}{Jeannette M. Wing, \emph{Computational
%%     Thinking}~\cite{wing_computational_thinking}} 

\makequotation{I think everyone should learn how to program a computer,
  because it teaches you how to think.}{Steve Jobs~\cite{steve_jobs_interview}}

Today, ``computer
literacy'' means familiarity with 
productivity tools such as email, Web browsers, word processors,
spreadsheets, and so on.  
But within the computer science community, discussions about computer
literacy are framed quite differently.  
In 1996, MIT computer scientist and educator
\w{Seymour Papert} coined the term \w{computational thinking} to
describe the mindset and types of techniques that
characterize a computer scientist's view of problem-solving.
Ten years later, an
\href{http://www.cs.cmu.edu/afs/cs/usr/wing/www/publications/Wing06.pdf}{influential op-ed} by Carnegie-Mellon University computer scientist
Jeannette Wing argued for the importance of computational thinking as a
skill set for the general 
public~\cite{wing_computational_thinking}, because it comprises
problem-solving skills of real practical value: why does your land-line
phone work during a power outage, but not your battery-powered cell phone?  At
what point should you stop renting skis and just buy a pair?  Which line
in the supermarket is likely to move fastest?  All of these problems are
``write down the answer'' problems from a computational thinking point
of view.

At the same time, we worry about the ``digital divide''
because we believe that citizens lacking good access to
computing tools will be disadvantaged in their professional and personal
lives.  But this ``divide'' is not just lack of access to computers, but lack
of any understanding of how they perform their tasks and therefore of
what makes them augmentors of human intellect.
In a 2006 Salon article \href{www.salon.com/2006/09/14/basic_2}{Why Johnny
  can't code},
David Brin laments that for
all its flaws, and despite its small view of the world (or perhaps
because of it), BASIC was sufficiently
nonthreatening to introduce an entire generation of newbies
to the joy of programming---exactly
the goals of its creators---whereas today's more expressive languages
for higher-powered platforms may scare beginners away.

\begin{geeknote}
Many angry responses to Brin's article commented on the fact that BASIC
does indeed instill habits contrary to modern OO programming practices,
that powerful scripting languages like Perl and Python have filled BASIC's
niche, and so on.  These responses miss the point.  While Brin wasn't
praising BASIC specifically, Perl and Python (for example) are languages
targeted at professional programmers, not beginners, and they
reflect two decades of thinking and experience focused on a professional audience,
not an audience of students.  Perl's syntax is so idiosyncratic that I'd
never foist it on a beginner. Python is much better in this regard, but
still powerful enough that many implicit algorithm steps are elided for
the beginner because they are encapsulated in language constructs like
list comprehensions, regular expressions, and so on.
A site developed in response to Brin's article, 
\href{http://quitebasic.com}{Quite BASIC}, provides a simple in-browser
BASIC environment with medium-resolution color graphics, and is probably
the effort closest in spirit to what Brin praises.

\end{geeknote}

Tom Kurtz, a mathematics professor at Dartmouth, was concerned about all
these same things in 1962.
However, given the speed at which the computing revolution has swept
civilization, it's challenging to put ourselves in his position and
understand his vision for universal computer access and literacy for
Dartmouth students.
Not only was there no mass-produced software as
there is today: software  had to be custom-written for \emph{each} new
computer, even models from the same manufacturer.  

  \begin{geeknote}
  The idea that
  you could upgrade your computer and continue to use your old software
  was completely foreign, and when IBM announced in 1964 that
  they were going to do this with the \w[System_360]{System/360}, it was a considered a bold,
  innovative, and risky ``bet the
  company'' move, yet one without which today's concept of ``backward
  compatibility,'' which we take for granted, would not have happened.
  \end{geeknote}

It was against this backdrop 
in 1962 that Kurtz approached
his department chair John Kemeny with a remarkably farsighted vision:
Since computers were clearly going to be important in everyday
life, \emph{all} Dartmouth students should learn to use them.  This was
particularly progressive for a liberal arts college,
over 75\% of whose students were majoring in nontechnical fields.~\cite{goto}
And in 1962, given the lack of mass-produced software,
computer literacy meant learning to
write simple programs.
Kurtz's proposal was bold: Rather than a
pay-as-you-go system typical of that time, in which students were
charged for computer time 
actually used,
Kurtz wanted it to be like using the library:
simply typing your valid student ID number at a terminal would get you
online, with no metering of time.

Of course, the practical obstacle to Kurtz's vision was that
computers were exceedingly expensive.  In 1962,  \w{mainframes}
cost hundreds of thousands of dollars, so only medium-to-large 
businesses or universities could afford them.  
The salaries of professors, technicians, and programmers were
cheap by comparison, so computers were used in a way that guaranteed
they would almost never be idle---maximizing the efficiency of computer
time rather than the efficiency of the tasks the human users were trying
to accomplish.
Prospective users would prepare programs on decks of punched
cards and submit these to a technician.  
% TBD picture of punched card
Hours or even days later, they
could stop by and pick up a printout with the results of their program run.
Most often, the results would be botched because of a simple error in
the program, which the user had to correct, re-punch the offending
cards, resubmit the job, and come back hours or days later.  This method
of working, called \w{batch processing}, is how all computers were used
at that time.  
% from \cite{ceruzzi}
It may seem odd today to have to wait hours or days for the results of a
running a computer progam, but at that time, given the speeds of information communication and
transportation, it was  normal for business
reports to be a few days out of date.

  \begin{geeknote}
  A necessary side-effect of never leaving the computer idle is long wait
  times for the users.  This is true in doctors' offices, at the DMV, or
  in any scenario in which users must wait in line for a resource---as
  computational thinking tells us!
  \end{geeknote}

For an audience of liberal arts students who had no ``career
motivation'' to learn computer arcana, punched cards and their associated
rituals would be too high a hurdle.
Fortunately, a technical milestone helped save the day.

Part of the history of BASIC is that at every point where a
technological breakthrough has increased the potential reach of
computing or helped democratize it further, BASIC was there.  The first
such moment occurred when
Professor John McCarthy, then at MIT, suggested that Kurtz use
\w{timesharing}  for his project---one of the important technological
innovations of that era of computers, even though it wasn't being taken
very seriously in industry at that time.

\begin{milestone}{Timesharing}
Timesharing had recently been prototyped at
MIT~\cite{corbato62timesharing} as a way to give more users interactive
access to a computer, at a time when
batch processing was dominant.
The relatively inexpensive Teletype
\w{ASR-33} printing terminal had just been introduced (1963): at \$700,
it was much cheaper than its competitors the IBM 1050, 
(\href{http://www.science.uva.nl/museum/ibm1050.php}{photo}) and
Friden Flexowriter (10 bytes/sec,
\href{http://retrotechnology.com/herbs_stuff/flex_behr.html}{\$2500-4000})
printing terminals.
% photos of ASR-33, Flexo, and IBM 1050; pointers to Comp Hist Museum
\end{milestone}

Up until now, batch processing had been the only model.
But timesharing gave each user the illusion of having her own computer,
allowing quick turnaround between completing your program and running
it to see if it works.
Kurtz and Kemeny considered this a clincher for helping beginners.
They would design their system to be
interactive, assuming the availability of a timesharing system.  The
decision was fateful: besides ultimately meeting the creators' goals
of ease of use, it made BASIC the first programming language in which
your program could wait for the user to type something before
proceeding, making interactive computing a reality not only for the
creators of programs but for their users as well.

Today, universities with world-class computer science
departments like to boast that their introductory programming courses
reach over 90\% of
students across all departments (need cite), but
Dartmouth achieved this in 1971~\cite{man_and_computer} by instituting the farsighted 
vision of BASIC's creators.

\section{DARTMOUTH COLLEGE, 1964: FOCUS ON SIMPLICITY}

\makequotation{In cases where there is a choice between simplicity and efficiency,
simplicity is chosen\ldots{}no attempt will be made at making the use of the Time Sharing 
equipment be compatible with \emph{standard use of a computer.}}{Time Sharing Project Memorandum \#1,
Dartmouth College, November 6, 1963~\cite{hopl}} 

\picfigure{figs/ASR33.jpg}{fig:ASR33}{The Teletype ASR-33 printing
  terminal.}

Dartmouth had obtained a GE-225 computer system from General Electric
via two National Science Foundation research grants and
an educational discount from GE.  It was a bold decision that the
``environment'' in which beginners would learn programming need not have
anything in common with the environment used by scientists and engineers
to do their work (the ``standard use of a computer'' in the quote above).


Kemeny tried to convince Kurtz to use a subset of FORTRAN~I, which had
debuted with great success in 1957 as a language for scientists and
engineers to express mathematical problems.  
But Kurtz felt strongly that even existing high-level
languages, which had been designed for domain experts such as scientists
(FORTRAN) or business people (COBOL) 
had enough idiosyncrasies, quirks, and arbitrary rules of syntax and
semantics to interfere with lay people's ability to focus on the
concepts.  
And whereas FORTRAN had to be designed to be performance-competitive with
handcrafted assembly language programs, 
only \emph{reasonable} performance was necessary for BASIC, so the
design focused on 
ease of use.

For example, FORTRAN variable names beginning with letters I
through N always represented integers, whereas other variables represented
real numbers; in BASIC, a number is a number, and automatic type
promotion takes care of converting between integers and reals.  In
fact, BASIC didn't even require you to declare your variables in
advance of assigning them, as FORTRAN did.  FORTRAN's
conditional statement had the form 
\T{IF}~\emph{condition,label1,label2,label3}, leaving the reader to
understand the meaning of the punctuation and how the three labels
relate to the evaluation of the condition; BASIC uses English
words and a two-way
conditional---\T{IF}~\emph{condition}~\T{THEN}~\emph{label}---to
clarify intent.  FORTRAN's \T{DO} loop body always executes at least once,
even if the condition at the top of the loop is initially false; not
so for BASIC's \T{FOR\ldots{}NEXT} loop.

BASIC borrowed good ideas from other languages.  Like COBOL, every BASIC
statement starts with an English verb.  (This was true in the original
BASIC, though not always in Street BASICs.)  The language's simple
design made it possible for the compiler to be implemented by a team of
undergraduates: the first BASIC had only 14 commands, and used notation
for arithmetic 
equations that would be familiar to anyone with high school algebra knowledge.


  \begin{geeknote}
   This characteristic was exploited by Woz's Apple Integer BASIC and by
   Sinclair ZX80 BASIC to 
    provide a context-sensitive syntax checker that verified the syntax
    of your BASIC program lines as you typed them, rather than at
    runtime~\cite{zx80_basic_techreport}.  Woz's BASIC also stored the
    program in a parsed form that distinguished different uses of the
    same BASIC keyword, saving time during execution.
  \end{geeknote}

The original 1964 BASIC manual~\cite[p. 14]{dartmouth_basic_manual}
makes clear that the
creators' intent was a beginner-friendly ``BASIC programming appliance'' 
After a short (10-page double-spaced) exposition of BASIC itself, the
manual explains the steps students must take to begin writing programs: 
type \T{HELLO} at an ASR-33
Teletype, enter your student ID number when asked, 
and then type the name of the system you want to use (\T{BASIC}).
That's the entire contents of the section on ``how to use the computer
system'': three pages, one of which is a full-page diagram of the ASR-33
keyboard 
explaining weird keys such as \T{CTRL} to typists in 1964.
Given that most batch-processing systems required programmers to
learn and use a 
separate \w{job control} language to add 
job-management cards to the card deck, shielding novices from this
distinction was a bold move, and one that would remain a characteristic of
PC BASICs, in part necessitated by the low cost and
modest resources of those machines.

% (film: montage of power-on sequences of various home computers)


BASIC was also influenced by the technology of the time.  
FORTRAN was used in batch mode, so the order of program statements was
determined by the order of the punched cards in the program deck, since
each statement required its own card.
%% With CRT terminals years away, how to specify the order of statements in
%% a BASIC program?  Indeed, how to shield beginners from having to learn
%% to work with other elements of the computer system, such as files and editors?
Kemeny and Kurtz came up with an ingenious solution to the problem of
how to specify the order of BASIC statements: each line in a BASIC
program would begin with a line number, and the program would be
executed in order of ascending line numbers.
Typing a line of text consisting of a number followed by a BASIC statement
would create (or replace) that line in the current program.
Typing a line of text consisting of only a line number would delete that line.
Typing \T{LIST} would show
you all or part of your program in line-number order.
\T{SAVE} stored a copy of the current program with a name
chosen by the programmer, \T{OLD} (later \T{LOAD} in Street BASIC)
retrieved a previously-stored program, and \T{NEW} erased the current
program in order to start new work.  All of these commands were part
of the language.

  \begin{geeknote}
  The convention of line numbers was retained in virtually all ``street
  BASICs'' long after cursor-addressable CRT terminals were ubiquitous,
  and was finally dropped in Microsoft Visual Basic (although many modern
  BASICs, including VB, still allow them).
  \end{geeknote}

A more pronounced example that's often overlooked is BASIC's \T{INPUT}
statement, which means ``At this point in the program, stop and wait for
the user to type something, then record what was typed and proceed.''
Before timesharing, this concept was absent from programming, since the
idea of the computer stopping and waiting for a human to type was
ludicrous.  But since timesharing used that ``wasted'' waiting time to
serve other users, the idea of programs that would interact with the
user became a reality, and BASIC was the first high-level language to
support this concept directly.  (FORTRAN programs had to be accompanied
by a stack of ``data cards'' specifying the particular values on which
the program would operate, and a \T{READ} statement in the language
would consume the values from the data cards.)

These examples show how Kurtz and Kemeny worked around the technology of their
time without cluttering the concepts that beginners would learn.




\section{PALO ALTO, 1970: COMPUTING FOR EVERYONE}

%  what did 'universal access' mean in the culture of 1970 CA?

Fast forward to 1970 California, when the first personal computers (Altair,
Mark-8) were becoming available.  Bob Albrecht, a refugee from computer
maker Control
Data, had become uneasy with the industry's emphasis on computers for
corporations rather than people.  He 
started the People's Computer Company in Menlo Park, a nonprofit walk-in
computer center where anyone could walk in and pay per hour to use
terminals connected to a PDP-8 and (later) a remote HP computer on which
HP had donated time.  People wrote and ran small-business programs, played games
(mostly written in BASIC), and so on.
A frequent visitor was Ted Nelson, who, like Kurtz, believed computers
would be important and everyone should learn about them (``You can and
you must understand computers now!'')

Albrecht convinced colleague Dennis Allison,
idealistic Stanford lecturer, to create an \w{open source} \w{Tiny BASIC} that
would run on the emerging PCs, most with less than 4KB RAM, so that
programming might be accessible to all.  Dennis and
Bob started Dr. Dobb's Journal (the name is a contraction of their names)
as a sister publication to the 
People's Computer Company newsletter to publish information about Tiny BASIC.

\begin{milestone}{Open source}

\end{milestone}

\section{CAMBRIDGE, 1975: BILL GATES, PAUL ALLEN, AND ALTAIR BASIC}

\begin{milestone}{The microprocessor}

\end{milestone}

% transition/tech milestone: the microprocessor - 4004, 8008, 8080

\makequotation{%
Interviewer: What do you consider your greatest achievement ever in
programming? \\
Bill Gates: I'd have to say BASIC for the 8080, because of the effect it's
had, and because of how appropriate it was at the time, and because we
managed to get it so small. It was the original program we wrote when we
decided to start Microsoft.}{Bill Gates~\cite{smithsonian_interview}} 

Allen and Gates had same goal as Bob Albrecht---computing for the
masses---but not the 
same open source mentality.  In a feat of programming that Bill Gates
says is still his proudest moment, he squeezed a relatively featureful
and performant interpreter into the Altair's 4KB RAM.  (Gates had
previously written a BASIC interpreter for  a DEC PDP-10 in high school and
had learned a lot from the experience.)  With 4KB and the nonexistent
OS/runtime, an interpreter would ahve to be the way to go, even though
Dartmouth BASIC had always been load-and-go compiled.

In 1971, DEC engineers had developed a timesharing runtime system called
RSTS-11 (``Resource sharing time sharing'') for the newly-announced
PDP-11.  
RSTS-11 was implemented entirely in BASIC, 
which DEC had
extended with three new commands to allow interaction with the underlying
machine: \T{SYS} to call a machine language routine (system call), and
\T{PEEK} and \T{POKE} to query and set the contents of individual memory
locations (like C pointers)~\cite[pp.~204--205]{ceruzzi}.
All three appeared in Gates's original Altair
BASIC~\cite{smithsonian_interview}, with \T{SYS} 
renamed to \T{USR} for User Service Routine, and
all would turn out to be critical for PC adaptations of 
BASIC. 


``\ldots I'm a big believer in interpreted languages,
not only from the beginning of computing, but the future of
computing. It was really the right approach, because you could just type
the thing in and immediately see what was happening. And yet you could
add new capabilities very easily.'' ~\cite{smithsonian_interview}


Gates retained
Monte Davidoff to write the floating-point math package.
At the time, there was no standard for how to handle real arithmetic in
computer languages, so Davidoff designed his own scheme, probably based
on the techniques used by the popular DEC computers of that time and
which would eventually inform the industry standard.
Squeezing a well-featured BASIC that included real arithmetic into just
4096 bytes of 8080 assembly language was a feat indeed, and Gates later
recounted that the extensive tuning required to squeeze everything in
gave the authors confidence that no one could improve on their
work~\cite{programmers_at_work}. 

  \begin{geeknote}
  A standard would finally be developed by a committee convened by Intel
  and other vendors and then endorsed by the Institute of Electrical and
  Electronics Engineers, a vendor-neutral professional and scholarly
  society, as IEEE~754.  \w{William Kahan} ultimately received the
  Turing Award for his work on this difficult problem~\cite{kahan_interview}.
  \end{geeknote}

In early days of computers, HW was the real thing and SW was an
afterthought.  Programming was seen as glorified clerical/grunge work.
Hence, the knowledge of how to do it was viewed as something to be
shared freely, since the belief was that the hardware was the
competitive/proprietary advantage.
Gates would learn that in an environment dominated by this
``share-alike'' mindset, it was
tricky to sell individual copies of software and expect people not to
copy them.  Gates
expressed his disdain at the ``software pirates'' (first use of term??) in infamous
1976 open letter.
Gates quickly figured out that it was better to license BASIC to
computer manufacturers to place in ROM, similar to how Windows would be
licensed later to be preinstalled, rather than sell copies to
hobbyists.  Radio Shack and TI were the first two, with Apple shortly
thereafter.  

From CBASIC to visual BASIC....


First popular BASIC game: startrek.bas?
  - on non-XY-addressable text displays

Getting off the ground: Microsoft BASIC and the Altair 8800.  Why was
    BASIC chosen?


How did constraints of BASIC affect programs written:
- for business?
- for entertainment?



Platform constraints as virtues:
 - ZX80 "Hampson's Plane" uses blackout during display generation 
 - ZX80 and other BASICs where "Save" saves BASIC memory image incl
 variable values (save game?)

\section{VALLEY FORGE, 1975: THE 6502}

\begin{milestone}{The 6502}
% milestone: the 6502.  made truly inexpensive home computers possible
% (with all due respect to sinclair)

\end{milestone}

Peddle, Mensch, Motorola 6800, resistance to doing cheaper part.

Left company, joined MOS, which had as a goal to be the best process
company: it developed contactless masks (which last forever, as opposed
to contact masks that wear out after stamping out some number of dice)
and a technique for fixing masks after they had been produced.  With
these advantages and careful tuning, they achieved yields of 70\% at a
time when 30\% was common.  The high yields and small die size
(per-chip costs were dominated by packaging) allowed them to produce the
chips for under \$12 and sell them for \$20-25.

Original goal was compete with 4040 and 4004---not 8080!  \$20 price
point was to get ``design wins'' in embedded systems and ``put
microprocessors everywhere''~\cite{commodore}.

4300 transistors

Pin-compatible and largely assembly-code-compatible, but
machine-code-incompatible, with 6800; to take advantage of 
6800 hobbyist kits and existing software.

\$20 in quantity 1!  8080 was \$150 in quantity at that time (check?).
%% In 1974, HP introduced the HP-65 programmable calculator, Intel
%% announced the 8080, and (in December) \emph{Popular Electronics} had the
%% Altair 8800 on the cover.  
The 8080 sold for \$360 in small quantities and \$75 to Altair 
in large quantities~\cite[p. 228]{ceruzzi}.

    \begin{geeknote}{Good taste in what to leave out}
Compared to 6800, 6502 lacks a second accumulator, and can't
tristate the address bus (so you can't do DMA, but that was seen as
unnecessary for small systems).~\cite{byte75:6502}.
Since registers were expensive and RAM wasn't much slower than
clock speeds, RAM was used as registers, especially the ``zero
page'' (bytes 0x0000 to 0x00ff in the 6502 address space), whose
special load and store instructions were shorter to fetch and
faster to decode.
Other frequently used instructions, including conditional relative
branch and subroutine calls, were 1 to 3 cycles faster on 6502 than
on comparable microprocessors.
The 6502 also ditched the 6800's 16-bit index register for a pair
of 8-bit index registers that could be used for two different types
of indirect addressing.
This decision was based on designer Chuck Peddle's experience with real
code: for programs that need to reference arrays based on random
offsets (vs. simply walking through them) or do operations that
maintain pointers into two arrays, the 6502's extra addressing modes
reduce instruction count and execution time by up to a
factor of 2 over the 6800.
Indeed, ``The 6502's superior performance on the AH Systems benchmarks
(winning four out of five of them over the 8080 and 6800) would, if
accurate, indicate that [the] shift in emphasis to improved addressing
has worked.''~\cite{edn75:6502}.
    \end{geeknote}


Stan Veit reported that when he demonstrated the Apple I at an ACM (New
York chapter) dinner meeting in 1976, his colleagues were
astonished---but the dealers' reaction was please call when BASIC is
available.  Jobs said Woz was ``working hard'' on an
interpreter~\cite[pp. 92ff]{veit}.
On August 26, 1976, at the first national computer show in Atlantic City,
NJ, Woz was in the hotel room using the hotel room's TV to finish work
on BASIC; it worked on their floor models when the show opened on August
28.  It was the only 6502 computer on a floor full of 8080s

Whereas the PET and TRS-80 (introduced around the same time as the Apple
II) were great hobbyist intro machines, The Apple II was the first PC
sufficiently powerful to run serious programs like VisiCalc yet
sufficiently inexpensive (due to its elegant design and the inexpensive
6502) to be accessible to hobbyists, so it deserves credit for
catalyzing the ``cottage industry'' of professional software
development.
(check this)

Not fast enough as performance language, but primitive 'scripting
language' if underlying runtime system allowed access to 'interesting'
behaviors (eg graphics); esp prevalent in late PCs (VIC, C64), Visual
BASIC (scripting MS Office), and finally VB.net


Street BASIC may have corrupted the language, but the tradeoff was that
it was used to write influential production software.

Ironically, for all the authors' critiques of ``street BASIC,'' its user
experience was quite close to the ``appliance'' view: starting with the
Apple II Plus (?check this; maybe TRS-80 model I?), most home computers
didn't have hard disks or at first even floppies to boot from, so they
``booted'' into a BASIC interpreter in ROM.  The first thing the user
would see was a BASIC prompt. 


What it was like
  - ROM BASIC vs "true" OS.  TO most of us who grew up on BASIC, it
  *was* the OS, shell, ...
  - BASIC and I/O - OS facilities: an uneasy marriage.  Compare GWBASIC,
  TRSBASIC level 2, Applesoft/Integer BASIC + DOS

What had changed by the time BASIC was ported to PCs?
-  Graphics (albeit all mutually incompatible)
-  Need for combining BASIC and machine language
-  needed to work with memory-mapped IO (joysticks, etc)


BASIC and graphics: a way to do entertainment and games
  - ZX80, TRS-80: graphic character glyphs, plus most BASICs provided "gotoXY"
  - Apple II: lo-res graphics mode repurposes text glyphs
  - Apple II: weirdly memory-mapped hires graphics library; shape tables
  - VIC-20, C64
  - Famous graphics demos in BASIC: Fire Organ, moire pattern, breakout
  (Woz added graphics and PDL() commands to IntBasic just to be able to
  recreate Breakout)

As popular press vehicle for computing
  - "BASIC games" books
  - type-in listings



\section{Influential Production Software Written in BASIC}

% milestone: consumer-priced modems => BBSs, and the C64
%   anything good form BBS: The Documentary?

\makequotation{Whether we're still programming in it or not, the spirit
  of BASIC lives on in all of us.}{Jeff Atwood, founder of
  StackExchange.com, author of Coding Horror blog~\cite{codinghorror_basic}}


As implementation of commercial software - strategy games
  - Invasion Orion - from Autoamted Simulations - all their games were
  in BASIC and could be listed, modified, etc.
  - SAGA - first one Pirate's ADventure was in BASIC, but using an
  ``Adventure intepreter'' implemented in TRS-80 Level II BASIC!  SOurce
  code is in Dec 1980 BYTE.
  - Broderbund Galactic Empire (TRS-80?)



\w{Odyssey: The Compleat Apventure} was an early (1980) adventure game
for the Apple~II.
Like prior text adventures such as Advent and Zork, the game is
turn-based, with the player using the 
keyboard to select one of a half-dozen or so possible actions
constrained by context: move in a certain direction, pick up an
available object, and so on.
Like its descendants, however, it made extensive (for the time) use of
graphics, using both the ``high resolution'' mode ($280\times 192$, 0 colors
depending on how you count) to display overall maps showing the player's
avatar and major landscape features (Figure~\ref{fig:odyssey_hires}), and the
``low resolution'' ($40\times 40$, 15
colors) modes of the Apple II.
The three main ``phases'' of the game were authored as separate programs
that shared data via disk files; a primitive overlay-like mechanism was
used to transition between phases.  
The various programs totaling 64~KiB of tokenized code were written in Apple II Integer
BASIC, the
original interpreter hand-coded in assembly by Steve Wozniak for
the Apple II before Microsoft adapted its floating-point BASIC for that
computer.  Between the game programs (64~KiB total), bitmaps of the ``hi-res''
maps (four at 8~KiB each), a few assembly routines to help with graphics
drawing (6.5~KiB), and the image of Integer BASIC, which had to be
included on any boot floppy that wanted to use it since Integer BASIC
was replaced by Applesoft BASIC in ROM early in the Apple II's lifetime,
the program nearly filled the 130~KiB floppy disk.

\section{ARCHAEOLOGY}

\B{BASIC Interpreters, Compilers, and Emulators.}

QuiteBASIC is my personal favorite for meeting the goal of a simple
BASIC that is beginner-friendly.  That said,
Microsoft's DevLabs 
released \href{http://smallbasic.com}{Microsoft Small Basic} in 2008 as a
Technology Preview plug-in to Visual Studio.
The idea is well-intentioned, although hardly small---Small Basic
requires Windows XP or later, meaning a 500
MHz x86 processor, several gigabytes of disk space, and at least 256
megabytes of RAM.
Also, because of Small Basic's explicitly
object-oriented syntax,  a novice must either understand why she
must say \C{TextWindow.WriteLine("Hello world")} to display text on the
screen or accept the arbitrariness of that syntax---one of the very problems
BASIC's creators set out to eliminate.  

A more authentic route for the historically-minded is to use emulators.
You can try a lot of the software yourself, and explore
its source code, thanks to the many great emulators available and the
collection of emulator-compatible disk images floating around the Internet.

\begin{itemize}

\item \href{http://quitebasic.com}{Quite BASIC} is a free in-browser BASIC
  interpreter that is probably closest in spirit to what David Brin
  lamented missing in his Salon article.  It has a graphics canvas
  allowing programs to do simple graphics.

\item \href{http://virtualii.com}{Virtual-][} is an extraordinarily
  faithful Apple II emulator, right down to the sound effects of
  whirring disk drives and dot matrix printing.

\item \href{http://web.archive.org/web/20011211231432/http://www.rjh.org.uk/altair/4k/em/altem.htm}{Altair emulator with BASIC} (Java applet emulator; doesn't run in Safari,
maybe needs earlier JRE?)

\end{itemize}


% computer history museum

\B{Old source code.}
There is a long saga about trying to get access to the original
Microsoft BASIC source code---the 8080 Altair BASIC authored by Bill
Gates, Paul Allen and Monte Davidoff that launched the PC revolution.
The true urtext is still elusive, believed to be locked in Bill Gates's
personal safe.
The Pusey Library at Harvard University has a copy (which you may
inspect but not photograph\ldots{}WTF?) annotated with version number
1.1.
You can read more about this archaeological quest at
\href{http://www.theregister.co.uk/2001/05/13/raiders_of_the_lost_altair/}{Raiders
of the Lost Altair BASIC Source Code}, The Register, May 13, 2001,
which tells the overall story.
\href{http://www.interact-sw.co.uk/altair/other\%20versions/ian.htm}{Quest
for the Holy Source: Ian's Trip to Harvard} tells about Ian
Griffiths's visit to the Pusey Library at Harvard to view version
1.1.
He reports that the library's copy includes a transmittal letter from
Harry Lewis, Dean of Harvard College and a professor of Computer
Science there, who reportedly found this copy of the source code behind
a cabinet in an old CS office.
The letter reports that other computer scientists, including Donald
Knuth, have made ``pilgrimages'' to Harvard to see this copy.

\href{http://www.drdobbs.com/back-to-the-future/184404733}{Bill's
  Lost Code} (a section of the Back to the Future column in this online
issue of Dr. Dobbs' Journal) observes that based on reading this source
code, Gates was indeed a craftsman and hacker, pulling nifty tricks such
as jumping into the middle of an instruction (because a multi-byte
opcode had a different interpretation if you started reading at the 2nd
or 3rd byte) to squeeze a BASIC interpreter into just 4KiB of ROM.

Reuben Harris, a London programmer, has created an
\href{http://web.archive.org/web/20011211233332/www.rjh.org.uk/altair/4k/index2.html}{annotated
disassembly of the actual Altair 4K BASIC} that you can visit thanks to the
Wayback Machine.


\section{ATTRIBUTIONS}

\begin{itemize}
\item ASR-33 image source:
  \href{http://en.wikipedia.org/wiki/File:Teletype_with_papertape_punch_and_reader.jpg}{Wikimedia
    Commons}, license: Creative Commons Attribution-ShareAlike 3.0
  Unported license, author: AlisonW.
\item 
\end{itemize}

\bibliographystyle{plain}
\bibliography{basic}

\end{document}
