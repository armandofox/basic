%% Copyright (C) 2013 by Armando Fox.  All rights reserved.

\documentclass{article}

\input{macros}

\title{In Praise of BASIC: The Cultural Impact of the World's Most
  Maligned Programming Language}
\author{Armando Fox}

\begin{document}


\maketitle

\noindent\framebox{\parbox{\textwidth}{
This document is under construction.  The version you are reading
sucks.  Ask Armando for a more up-to-date version, or check one out
yourself at GitHub from \T{armandofox/basic}.
}}

\makequotation{It is practically impossible to teach good programming to
  students that have had a prior exposure to BASIC: as potential
  programmers they are mentally mutilated beyond hope of
  regeneration.}{Edsger W. Dijkstra, Turing Award winner}

\makequotation{\ldots the teaching of BASIC should be rated as a
  criminal offence: it mutilates the mind beyond recovery.}{Edsger
  W. Dijkstra, Turing Award winner}

\makequotation{I think it's fair to say that more persons in the world know how to
write simple programs in BASIC than in any other language. It is true
that most of them are probably still unable to vote or buy a drink.  And
if FORTRAN is the lingua franca, then certainly it must be true that
BASIC is the lingua playpen.}{Thomas E. Kurtz in 1981~\cite{hopl}}

Current incarnations of BASIC (eg VB.net) bear little resemblance to
their ancestors.  But still, BASIC introduced an entire generation of
programmers to programming.  It inculcated many ``bad'' habits that
structured languages tried to break, but it taught us "computational
thinking" (qv).  To be fair, some bad habits were result of authors'
inability to adapt to fast commercialization, and/or limitations of
commercially attractive platforms (interpret vs compile; special
variable types for ints vs floats).

\section{Universal access and computational thinking}

\makequotation{Thinking like a computer scientist means more than being able to 
program a computer. It requires thinking at multiple levels of
abstraction.}{Jeannette M. Wing, \emph{Computational
    Thinking}~\cite{wing_computational_thinking}} 

Today, to most people who are not computer professionals, ``computer
literacy'' means familiarity with 
productivity tools such as email, Web browsers, word processors,
spreadsheets, and so on.  
But within the computer science community, discussions about computer
literacy are framed quite differently.  
In 1996, MIT computer scientist and educator
\w{Seymour Papert} coined the term \w{computational thinking} to
describe the mindset and types of techniques that
characterize a computer scientist's view of problem-solving.
Ten years later, an
\href{http://www.cs.cmu.edu/afs/cs/usr/wing/www/publications/Wing06.pdf}{influential op-ed} by Carnegie-Mellon University computer scientist
Jeannette Wing argued for the importance of computational thinking as a
skill set for the general 
public~\cite{wing_computational_thinking}, because it comprises
problem-solving skills of real practical value: why does your land-line
work during a power outage, but not your battery-powered cell phone?  At
what point should you stop renting skis and just buy a pair?  Which line
in the supermarket is likely to move fastest?  All of these problems are
``write down the answer'' problems from a computational thinking point
of view.

At the same time, we worry about the ``digital divide''---unequal access
to computing---because we believe that citizens lacking good access to
computing tools will be disadvantaged in their professional and personal
lives.

Tom Kurtz, a mathematics professor at Dartmouth, was concerned about all
these same things in 1962.
However, given the speed at which the computing revolution has swept
civilization, it's challenging to put ourselves in his position and
understand his vision for universal computer access and literacy for
Dartmouth students.
Not only was there no mass-produced software as
there is today: software  had to be custom-written for \emph{each} new
computer, even models from the same manufacturer.  
  \geeknote{The idea that
  you could upgrade your computer and continue to use your old software
  was completely foreign, and when IBM announced in 1964 that
  they were going to do this with the \w[System_360]{System/360}, it was a considered a bold,
  innovative, and risky ``bet the
  company'' move, yet one without which today's concept of ``backward
  compatibility,'' which we take for granted, would not have happened.}
It was against this backdrop 
in 1962 that Tom Kurtz, a mathematics professor at Dartmouth, approached
his department chair John Kemeny with a remarkably farsighted vision:
Since computers were clearly going to be important in everyday
life, \emph{all} Dartmouth students should learn to use them.  This is
particularly progressive given that Dartmouth was a liberal arts college,
with fewer than 25\% of students intending to major in technical fields that might
plausibly require computer skills.~\cite{goto}
And in 1962, given the lack of mass-produced software,
becoming computer literate meant learning to
write simple programs.

But the practical obstacle to Kurtz's vision was that
computers were exceedingly expensive.  In 1962,  \w{mainframes}
cost hundreds of thousands of dollars, so only medium-to-large 
businesses or universities could afford them.  
The salaries of professors, technicians, and programmers were
cheap by comparison, so computers were used in a way that guaranteed
they would almost never be idle---maximizing the efficiency of computer
time rather than the efficiency of the tasks the human users were trying
to accomplish.
Prospective users would prepare programs on decks of punched
cards and submit these to a technician.  
% TBD picture of punched card
Hours or even days later, they
could stop by and pick up a printout with the results of their program run.
  \geeknote{A necessary side-effect of never leaving the computer idle is long wait
  times for the users.  This is true in doctors' offices, at the DMV, or
  in any scenario in which users must wait in line for a resource---as
  computational thinking tells us!}
Most often, the results would be botched because of a simple error in
the program, which the user had to correct, re-punch the offending
cards, resubmit the job, and come back hours or days later.  This method
of working, called \w{batch processing}, is how all computers were used
at that time.


In 1963 Dartmouth decided to
institutionalize his vision, and Kemeny reported in
1971~\cite{man_and_computer} that
% better to cite Smithsonian or AMNH lecture on which book is based??), 
over 90\% of the students in the previous seven freshman classes had
received computer training.  Today, schools like Stanford boast about
CS service courses taken by over 90\% of campus (need cite), but
Dartmouth was there in 1971 due to Kurtz and Kemeny's farsightedness.

For that audience, punched cards and the associated rituals would be too
high a hurdle.
Fortunately, timesharing had recently been prototyped at
MIT~\cite{corbato62timesharing} and the relatively inexpensive Teletype
\w{ASR-33} printing terminal had just been introduced (1963); at \$700,
much cheaper than its competitors the IBM 1050
(\href{http://www.science.uva.nl/museum/ibm1050.php}{photo}) and
Friden Flexowriter (10 bytes/sec,
\href{http://retrotechnology.com/herbs_stuff/flex_behr.html}{\$2500-4000})
printing terminals.
% photos of ASR-33, Flexo, and IBM 1050; pointers to Comp Hist Museum
So John McCarthy suggested that Kurtz use that approach for his project,
even though timesharing wasn't being taken very seriously in industry at
that time.

Rather than a
pay-as-you-go system, Kurtz wanted it to be like using the library:
simply typing your valid student ID number at a terminal would get you
online.


\section{Focus on Simplicity: a ``BASIC Appliance''}

% REM DARTMOUTH, 1964

%% tech milestone: timesharing

\makequotation{``In cases where there is a choice between simplicity and efficiency,
simplicity is chosen\ldots{}no attempt will be made at making the use of the Time Sharing 
equipment be compatible with \emph{standard use of a computer}''}{Time Sharing Project Memorandum \#1,
Dartmouth College, November 6, 1963~\cite{hopl}} 

Although the Dartmouth system (GE-225, obtained via two NSF grants and
an educational discount from GE) would be used for a variety of
educational and research purposes, 

At the time, MIT had been experimenting with timesharing.
 Up til then,
batch had been the only model.  The idea of the illusion of having one's
own computer meant quick turnaround time to test your programs and get
feedback to see if they work.  Kurtz and Kemeny considered this a
clincher, so they would design their language and its runtime system to
be interactive.

``...[my italics].

From the original 1964 manual (cite), it's clear that the creators had
in mind the idea of a ``BASIC appliance''.  After a short 10-page
(double spaced!) exposition of BASIC itself, the manual
explains the procedure for students: type \T{HELLO} at an ASR-33
Teletype, and in response to its questions, type your student ID number
and the name of the system you want to use (BASIC).  That's the entire
contents of the  3-page section on how to ``use the computer system'',
one of which pages is a diagram of the ASR-33 keyboard,
to explain keys such as CTRL that would have been unfamiliar to
typists in 1964.

% (film: montage of power-on sequences of various home computers)

Kurtz felt strongly that even existing high-level
languages, which had been designed for domain experts such as scientists
(FORTRAN) or business people (COBOL) 
had enough idiosyncrasies, quirks, and arbitrary rules of syntax and
semantics (eg the FORTRAN "IJKLMN" rule, syntax of punctuation, 3-way
conditional of FORTRAN I) to put off lay people.  Unlike FORTRAN,
only reasonable performance was a goal; the design principles focused on
ease of use.


Examples:

Good ideas borrowed from other languages:

Every statement starts with an English verb (COBOL).
  \geeknote{This characteristics was exploited by Sinclair ZX80 BASIC to
    provide a context-sensitive syntax checker that verified the syntax
    of your BASIC program lines as you typed them, rather than at
    runtime~\cite{zx80_basic_techreport}.}

Bad ideas ditched from other languages:

FORTRAN's 3-way branch was replaced with 2-way branch that uses English words (IF,
THEN) instead of punctuation (FORTRAN I)

Required declarations (FORTRAN and others)

No distinction between floats and ints (FORTRAN IJKLMN convention)

FORTRAN was used in batch mode, and program statements were typically
ordered by ordering the cards in the program deck, but how to order the
statements in a BASIC program with no cards?

What distinguishing hardware/OS features were contemporaneous with BASIC
and set it apart from other languages and/or constrained/influenced its
initial design?

Timesharing was new => INPUT statement - first language-level support for
   interactivity  (?).  Real game changer whose existence made it necessary
for BASIC to be interactive!  (vs FORTRAN READ/DATA)


Likewise: At the time of BASIC's invention (1964), CRT terminals were still six
years away, so all timesharing interaction occurred via printing
terminals such as the early Teletype ASR-33.
The creators came up with an ingenious solution: each line in a BASIC
program would begin with a line number, and the program would be
executed in order of ascending line numbers.
Typing a line of text consisting of a number followed by a line of code
would create (or replace) that line of code in the current program.
Typing a line of text consisting of a number would delete that line of
code (or replace it with a blank line) in the current program.
  \geeknote{The convention of line numbers was retained in virtually all ``street
  BASICs'' well after cursor-addressable CRT terminals were ubiquitous,
  and was finally dropped in Microsoft Visual Basic (although many modern
  BASICs, including VB, still allow them).}


Primitive first-gen and second-gen OS's => runtime interaction with user
is part of language's runtime system (UCSD Pascal would do this later?),
vs separate command shell in OS (since most OS's weren't interactive and
instead relied on job languages/job cards).
In BASIC, can't easily separate "runtime system" and OS from language: commands
like LIST, NEW, OLD effectively became part of the language for its
users (TBD are they in the standard??)  This would be true in ``street
BASIC'' as well.


Programs were typed on printing terminals (Teletype ASR-33s) rather than
being punched onto cards that were ordered in a deck; hence, each
statement was preceded by a number when typed, and statements would be
executed in numerical order even if typed out of order, and displayed in
order when the runtime was ordered to list the program.



The first BASIC had only 14 commands, and notation for arithmetic
equations that would be familiar to anyone familiar with high school algebra.

\section{Computing for Everyone: The Flower People}

% REM PALO ALTO, 1970

%  what did 'universal access' mean in the culture of 1970 CA?

Fast forwrd to 1970 California; the first personal computers (Altair,
Mark-8) were becoming available.  Bob Albrecht, a refugee from Control
Data who became uneasy with the industry's emphasis on computers for
corporations rather than people, 
started the People's Computer Company in Menlo Park, a nonprofit walk-in
computer center where anyone could walk in and pay as they went to use
terminals connected to a PDP-8 and (later) a remote HP computer on which
HP had donated time.  People did small business stuff, played games
(mostly in BASIC), and so on.
A frequent visitor was Ted Nelson, who, like Kurtz, believed computers
would be important and everyone should learn about them ("You can and
you must understand computers now!")
Albrecht convinced colleague Dennis Allison,
idealistic Stanford lecturer, to create an "open source" \w{Tiny BASIC} that
would run on the emerging PCs, most with less than 4KB RAM, so that
programming might be accessible to all.  Dennis and
Bob started Dr. Dobb's (Dennis+Bob's) Journal, sister publication to the
PCC newsletter, to publish information about Tiny BASIC.

\section{Bill Gates, Paul Allen, and Altair BASIC}

% REM CAMBRIDGE, 1975

% transition/tech milestone: the microprocessor - 4004, 8008, 8080

\makequotation{%
Interviewer: What do you consider your greatest achievement ever in
programming? \\
Bill Gates: I'd have to say BASIC for the 8080, because of the effect it's
had, and because of how appropriate it was at the time, and because we
managed to get it so small. It was the original program we wrote when we
decided to start Microsoft.}{Bill Gates~\cite{smithsonian_interview}} 

Allen and Gates had same goal - computing for the masses - but not the
same open source mentality.  In a feat of programming that Bill Gates
says is still his proudest moment, he squeezed a relatively featureful
and performant interpreter into the Altair's 4KB RAM.  (Gates had
previously written a BASIC interpreter for  a mini in high school and
learned a lot from the experience.)  With 4KB and the nonexistent
OS/runtime, an interpreter would ahve to be the way to go, even though
Dartmouth BASIC had always been load-and-go compiled.


``This BASIC, although it was very much modeled on what had been at
Dartmouth, which was what I encountered when I used that first GE
time-sharing machine. We'd gone beyond it in a number of ways to let
people add machine language sub-routines. Even new words in the language
like PEEK and POKE to let you read and write memory locations, were
starting to come up here. I'm a big believer in interpreted languages,
not only from the beginning of computing, but the future of
computing. It was really the right approach, because you could just type
the thing in and immediately see what was happening. And yet you could
add new capabilities very easily.'' Bill Gates~\cite{smithsonian_interview}:


Three of us knew that original program by heart. We got a chance to
completely rewrite it one summer down in Albuquerque, and I thought we
could save a few bytes and tighten things up. We just tuned the program
very, very carefully, and ended up with a 4K BASIC interpreter.

When you know a program that well, you feel that nobody can look at the
code and say, ``There's a better way to do this.'' That feeling's really
nice, and the fact that the program was used on a lot of machines makes
it an exciting program to have written.

---from \cite{programmers_at_work}


Monte Davidoff and math package: did it really fit in 4K?  No IEEE FP
standard so had to devise his own representations; apparaently
(http://web.archive.org/web/20011102002853/http://www.rjh.org.uk/altair/4k/math\_ex.htm)
he made similar choices to what would later be codified in IEEE.  (Ask
Velvel about this?)


In early days of computers, HW was the real thing and SW was an
afterthought.  Programming was seen as glorified clerical/grunge work.
Hence, the knowledge of how to do it was viewed as something to be
shared freely, since the belief was that the hardware was the
competitive/proprietary advantage.
Gates would learn that in an environment dominated by this
``share-alike'' mindset, it was
tricky to sell individual copies of software and expect people not to
copy them.  Gates
expressed his disdain at the ``software pirates'' (first use of term??) in infamous
1976 open letter.
Gates quickly figured out that it was better to license BASIC to
computer manufacturers to place in ROM, similar to how Windows would be
licensed later to be preinstalled, rather than sell copies to
hobbyists.  Radio Shack and TI were the first two, with Apple shortly
thereafter.  

From CBASIC to visual BASIC....


What had changed by the time BASIC was ported to PCs?
   Graphics (albeit all mutually incompatible)
   Need for combining BASIC and machine language (PEEK/POKE - what's
   history of these?) since you "owned" the address space anyway, and
   needed to work with memory-mapped IO (joysticks, etc)

First popular BASIC game: startrek.bas?
  - on non-XY-addressable text displays

Getting off the ground: Microsoft BASIC and the Altair 8800.  Why was
    BASIC chosen?

What it was like
  - ROM BASIC vs "true" OS.  TO most of us who grew up on BASIC, it
  *was* the OS, shell, ...
  - BASIC and I/O - OS facilities: an uneasy marriage.  Compare GWBASIC,
  TRSBASIC level 2, Applesoft/Integer BASIC + DOS

BASIC and graphics: a way to do entertainment and games
  - ZX80, TRS-80: graphic character glyphs, plus most BASICs provided "gotoXY"
  - Apple II: lo-res graphics mode repurposes text glyphs
  - Apple II: weirdly memory-mapped hires graphics library; shape tables
  - VIC-20, C64
  - Famous graphics demos in BASIC: Fire Organ, moire pattern, breakout
  (Woz added graphics and PDL() commands to IntBasic just to be able to
  recreate Breakout)

As popular press vehicle for computing
  - "BASIC games" books
  - type-in listings

As implementation of commercial software - strategy games
  - Invasion Orion - from Autoamted Simulations - all their games were
  in BASIC and could be listed, modified, etc.
  - SAGA - first one Pirate's ADventure was in BASIC, but using an
  ``Adventure intepreter'' implemented in TRS-80 Level II BASIC!  SOurce
  code is in Dec 1980 BYTE.
  - Broderbund Galactic Empire (TRS-80?)


How did constraints of BASIC affect programs written:
- for business?
- for entertainment?

Not fast enough as performance language, but primitive 'scripting
language' if underlying runtime system allowed access to 'interesting'
behaviors (eg graphics); esp prevalent in late PCs (VIC, C64), Visual
BASIC (scripting MS Office), and finally VB.net


Ironically, for all the authors' critiques of ``street BASIC,'' its user
experience was quite close to the ``appliance'' view: starting with the
Apple II Plus (?check this; maybe TRS-80 model I?), most home computers
didn't have hard disks or at first even floppies to boot from, so they
``booted'' into a BASIC interpreter in ROM.  The first thing the user
would see was a BASIC prompt. 


Cultural impact: introducing entire generation of programmers to
computing.
In a 2006 Salon article \href{www.salon.com/2006/09/14/basic_2}{Why Johnny
  Can't Compute},
David Brin laments that for
all its flaws and despite its small view of the world (or perhaps
because of it), BASIC was sufficiently
nonthreatening to introduce newbies to the joy of programming---exactly
the goals of its creators---and that today's higher-powered languages
for more sophisticated platforms tend to scare people away.

Perhaps in response to this article, Microsoft's Devlabs 
released \href{http://smallbasic.com}{Microsoft Small Basic} in 2008 as a
Technology Preview plug-in to Visual Studio.
The idea is well-intentioned, although hardly small---Small Basic
requires Windows XP or greater and the Microsoft .NET framework,
requiring at least a 500
MHz x86 processor, a few gigabytes of disk space, and at least 256
megabytes of RAM.
Small Basic has an explicitly
object-oriented syntax.  Thus a novice must either understand why she
must say \C{TextWindow.WriteLine("Hello world")} to display text on the
screen or accept the arbitrariness of that syntax---the very problem
BASIC's creators set out to eliminate.  Indeed, the introduction to
Microsoft's own tutorial begins with a section ``The Small Basic
Environment,'' which talks about ``launching'' Small Basic.  In the
creators' original vision, there was to be \emph{no} distinction in the
novice's mind between the language and the runtime system.  As the
original Dartmouth BASIC manual explains on page
14~\cite{dartmouth_basic_manual}, after logging in to the timesharing
system, a user would type the single command \T{BASIC}---that would be the
extent of her interaction with the operating system.  Common operating
system functions such as input/output were handled by commands built
into the language, such as \T{SAVE} to save the current program in a
named file in the filesystem, \T{OLD} (later \T{LOAD} in ``street
BASIC'') to retrieve a program stored in the filesystem, and so on.


Platform constraints as virtues:
 - ZX80 "Hampson's Plane" uses blackout during display generation 
 - ZX80 and other BASICs where "Save" saves BASIC memory image incl
 variable values (save game?)

\section{The Onslaught: Street BASIC}

% REM COMMODORE, 1980s

% milestone: the 6502.  made truly inexpensive home computers possible
% (with all due respect to sinclair)

\section{Influential Production Software Written in BASIC}

% milestone: consumer-priced modems => BBSs, and the C64
%   anything good form BBS: The Documentary?

\makequotation{Whether we're still programming in it or not, the spirit
  of BASIC lives on in all of us.}{Jeff Atwood, founder of
  StackExchange.com, author of Coding Horror blog~\cite{codinghorror_basic}}


\w{Odyssey: The Compleat Apventure} was an early (1980) adventure game
for the Apple~II.
Like prior text adventures such as Advent and Zork, the game is
turn-based, with the player using the 
keyboard to select one of a half-dozen or so possible actions
constrained by context: move in a certain direction, pick up an
available object, and so on.
Like its descendants, however, it made extensive (for the time) use of
graphics, using both the ``high resolution'' mode ($280\times 192$, 0 colors
depending on how you count) to display overall maps showing the player's
avatar and major landscape features (Figure~\ref{fig:odyssey_hires}), and the
``low resolution'' ($40\times 40$, 15
colors) modes of the Apple II.
The three main ``phases'' of the game were authored as separate programs
that shared data via disk files; a primitive overlay-like mechanism was
used to transition between phases.  
The various programs totaling 64~KiB of tokenized code were written in Apple II Integer
BASIC, the
original interpreter hand-coded in assembly by Steve Wozniak for
the Apple II before Microsoft adapted its floating-point BASIC for that
computer.  Between the game programs (64~KiB total), bitmaps of the ``hi-res''
maps (four at 8~KiB each), a few assembly routines to help with graphics
drawing (6.5~KiB), and the image of Integer BASIC, which had to be
included on any boot floppy that wanted to use it since Integer BASIC
was replaced by Applesoft BASIC in ROM early in the Apple II's lifetime,
the program nearly filled the 130~KiB floppy disk.

\section{Archaeology Resources}

% computer history museum

\B{Old source code.}
There is a long saga about trying to get access to the original
Microsoft BASIC source code---the Altair/8080 BASIC authored by Bill
Gates, Paul Allen and Monte Davidoff that launched the PC revolution.
The true urtext is still elusive, believed to be locked in Bill Gates's
personal safe.
The Pusey Library at Harvard University has a copy (which you may
inspect but not photograph\ldots{}WTF?) annotated with version number
1.1.
Reuben Harris, a London programmer, has created an
\href{http://web.archive.org/web/20011211233332/www.rjh.org.uk/altair/4k/index2.html}{annotated
disassembly of Altair 4K BASIC} that you can visit thanks to the
Wayback Machine.
You can read more about this archaeological quest at
\href{http://www.theregister.co.uk/2001/05/13/raiders_of_the_lost_altair/}{Raiders
of the Lost Altair BASIC Source Code}, The Register, May 13, 2001,
which tells the overall story.
\href{http://www.interact-sw.co.uk/altair/other\%20versions/ian.htm}{Quest
for the Holy Source: Ian's Trip to Harvard} tells about Ian
Griffiths's visit to the Pusey Library at Harvard to view version
1.1.
He reports that the library's copy includes a transmittal letter from
Harry Lewis, Dean of Harvard College and a professor of Computer
Science there, who reportedly found this copy of the source code behind
a cabinet in an old CS office.
The letter reports that other computer scientists, including Donald
Knuth, have made ``pilgrimages'' to Harvard to see this copy.

\href{http://www.drdobbs.com/back-to-the-future/184404733}{Bill's
  Lost Code} (a section of the Back to the Future column in this online
issue of Dr. Dobbs' Journal) observes that based on reading this source
code, Gates was indeed a craftsman and hacker, pulling nifty tricks such
as jumping into the middle of an instruction (because a multi-byte
opcode had a different interpretation if you started reading at the 2nd
or 3rd byte) to squeeze a BASIC interpreter into just 4KiB of ROM.

\B{Emulators.}
You can try a lot of the software yourself, and explore
its source code, thanks to the many great emulators available and the
collection of emulator-compatible disk images floating around the Internet.

\begin{itemize}
\item \href{http://virtualii.com}{Virtual-][} is an extraordinarily
  faithful Apple II emulator, right down to the sound effects of
  whirring disk drives and dot matrix printing.

\item \href{http://web.archive.org/web/20011211231432/http://www.rjh.org.uk/altair/4k/em/altem.htm}{Altair emulator with BASIC} (Java applet emulator; doesn't run in Safari,
maybe needs earlier JRE?)



\end{itemize}

\bibliographystyle{abbrvnat}
\bibliography{basic}

\end{document}
