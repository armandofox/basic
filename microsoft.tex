
\section{CAMBRIDGE 1975 - GATES - ALLEN - ALTAIR}

% transition/tech milestone: the microprocessor - 4004, 8008, 8080

\makequotation{%
\emph{Interviewer:}\/ What do you consider your greatest achievement ever in
programming? \\
\emph{Gates:}\/ I'd have to say BASIC for the 8080, because of the effect it's
had, and because of how appropriate it was at the time, and because we
managed to get it so small. It was the original program we wrote when we
decided to start Microsoft.}{1994 interview with Bill Gates~\cite{smithsonian_interview}} 

Gates, a Harvard undergraduate, and his colleague Paul Allen, a
college dropout working as a programmer for Honeywell in Boston, had
shared an enthusiasm for computing since they were teenagers growing
up together in Seattle.
When the Altair 8800 was announced, Allen persuaded Gates that
personal computers were coming quickly.
Like Bob Albrecht and Dennis Allison, the pair immediately realized
that all those computer owners would need to write programs, as there
was no PC software industry at that time.
But where Albrecht and Allison viewed software as something to be
given away to democratize computing, Gates and Allen saw a business
opportunity.

Gates had previously created a version of the BASIC language on a DEC \w{PDP-10}
minicomputer as a high school project.
%% Unlike a compiler, in which the programmer must prepare the entire
%% program before it can be run, interpreters gave instantaneous feedback
%% as each new incremental piece of the program was entered.
%% Gates believed interpreters were better for learning because of this
%% instant feedback: ``[y]ou could just type the thing in and
%% immediately see what was happening.''~\cite{smithsonian_interview}
%% And interpreters can be implemented in less memory than compilers,
%% an important advantage given the paltry amounts of memory in early
%% entry-level PCs. (The entry-level Altair 8800 came with 4~KiB of RAM---that's
%% four kilobytes, or 4096 bytes, enough to hold about 28 full-length tweets.)
He and Allen now began creating a BASIC language interpreter that
would work on the Intel 8080, the microprocessor inside the
Altair~8800 and (they believed) the other personal computers
that would soon follow.
When Gates remarked during a dinner conversation at Harvard that he
didn't know how to make his BASIC interpreter correctly handle
arithmetic on decimal numbers (as opposed to integers, or whole numbers),
fellow student Monte
Davidoff chimed in with ``I can do that.''
At the time, there was no standard for implementing floating-point in
computer languages, so Davidoff designed his own scheme, probably
based on the techniques used by the DEC~PDP-10 and other DEC
minicomputers of that time.


  \begin{tangent}
  Implementing so-called
  floating-point arithmetic in a rigorous manner turned out to be so tough that Intel 
  and other chip vendors eventually convened a technical committee to
  research the problem, under the aegis of the Institute of Electrical and 
  Electronics Engineers (IEEE), a vendor-neutral professional and scholarly
  society. 
  UC~Berkeley professor \w{William Kahan}
  ultimately received the 
  Turing Award for
  leading the effort~\cite{kahan_interview}, whose results were codified as
  the \w[IEEE floating point]{IEEE-754} standard in 1985.
  \end{tangent}

  \begin{tangent}

Gates faced new problems in adapting BASIC to PCs.
How could Gates's BASIC interact with the underlying hardware of the
Altair, which was so primitive and underpowered that it had no OS at all?
The solution came from 
DEC's PDP-11 computer (successor to the PDP-10 Gates had
programmed in high school), whose
timesharing OS \w[RSTS/E]{RSTS} (``Resource sharing, time
sharing'') was implemented largely in BASIC.  (If this sounds crazy,
remember that the original BASIC was compiled, and that 
   Unix is implemented largely in C.)  DEC had added
three new commands to BASIC to allow programs to interact with the 
hardware: \T{SYS} to make a system call to a logical address,
and \T{PEEK} and \T{POKE} to directly query and set the contents of individual memory
one byte at a time (like using an \texttt{unsigned char~*}
pointer in C)~\cite[pp.~204--205]{ceruzzi}.
Gates put all three into Altair BASIC~\cite{smithsonian_interview},
with \T{SYS} renamed to \T{USR} for User Service Routine.  All three
survived in virtually every PC adaptation of BASIC.
  \end{tangent}

In an impressive feat of programming, Gates squeezed a feature-laden
and high-performing BASIC interpreter into the Altair's 4KiB of memory
(4,096 bytes, less than the length of 30 tweets).
Gates later recounted that the extensive tuning gave the authors
confidence of the superiority of their
work~\cite{programmers_at_work}.
The feat is even more impressive considering that none of the team had
access to an actual 8080 or Altair computer: the whole project was
done using another program called an emulator (also written by Gates),
which imitated the behavior of the 8080 on Harvard's student computer
system, and Allen wrote another program on the plane to Albuquerque
that would allow Gates's BASIC language to be laboriously loaded into
the Altair computer via its front-panel switches.
Only after Allen arrived in Albuquerque and ran the high-stakes demo
for the first time did the pair know conclusively that it worked!
Allen quickly set up shop in Albuquerque as Micro-Soft [sic], and
Gates officially dropped out of Harvard to join him.
Microsoft BASIC was not only the product that launched a juggernaut
company, it was also Bill Gates's baby.

But Gates and Allen now faced a cultural obstacle in trying to
commercialize their product.
In early days of computing, the excitement and innovation was around
hardware.
Programming was an afterthought---something you learned to do in order
to use your nifty new hardware.
If you were a computer company, software was something you gave away
for free to stimulate hardware sales.
The ``share-alike'' mindset promulgated by Albrecht and his California
colleagues wasn't helping: in Palo Alto's Homebrew Computer Club,
where a young Steve Wozniak would eventually demonstrate his homebuilt
computer that would launch Apple, it was considered socially
acceptable to make copies of software to give your friends, and it
enhanced your standing as a valuable club member.
The idea of a market in which consumers would pay just for software
was simply not in most people's sights.

But Bill Gates was not most people: in 1976 he described just this
vision, perhaps somewhat abrasively, in a now-infamous ``open letter
to computer hobbyists'' published in the MITS newsletter that all
Altair owners received.
In pointed language, Gates railed against the ``software pirates'' who
circulated paper tape copies of Micro-Soft BASIC, complaining that
they were stealing his work (Micro-Soft was charging \$150 per copy
for its BASIC) and making a third-party software industry financially
infeasible.
The culture clash could not have been greater.
Notwithstanding the hue and cry generated by the letter, Gates quickly
figured out that a better solution was to license BASIC directly to
computer manufacturers, who would burn it into the ROM of each
computer sold, much as a BIOS is today.
(This pattern would be repeated later with Windows, which would be
licensed by computer manufacturers to preinstall on new PC hard
drives, rather than being purchased and installed separately by the
end user.)

That is how Bill Gates successfully got BASIC running on the first
personal computer, but that computer was only accessible to hobbyists
who could solder and who would tolerate using something that looked
more like a piece of lab equipment.
The Altair had no way to accept or display text, let alone graphics,
without adding additional hardware.
Gates knew that a ``ready-to-run'' computer was inevitable, but he was
a programmer, not a hardware designer.
Fortunately, a hardware designer who had also been bitten by the BASIC
bug was taking up the challenge---not in northern California, nor even
in Boston in the shadow of academia, but in the unlikely town of
Valley Forge, Pennsylvania, where General George Washington had pulled
his army through the bitter winter of the American Revolution nearly
200 years before.



